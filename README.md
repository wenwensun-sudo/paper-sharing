# paper-sharing
## Table of Content

* [Object Reidentification](#Object_Reidentification)
   * Text-Image Reidentification
   * Visible-Infrared Reidentification
* [Pre-training](#Pre_training)
* [Prompting Learning](#Prompting_Learning)
* [Multimodal Large Language Models](#Multimodal_Large_Language_Models)
* [Cross-modal Retrieval](#Cross_modal_Retrieval)
* [Fine Tuning](#Fine_Tuning)
<span id="Object_Reidentification"></span>
## Object Reidentification
### Text-Image Reidentification
| Date   | keywords   | Institute   | Paper | Publication|  code  |
| :-------:| :-----:  | :----:  |:----:  |:----:  |:----:  |
| 2023  | Text-to-Image Person Retrieval |Wuhan University|  [Cross-Modal Implicit Relation Reasoning and Aligning for Text-to-Image Person Retrieval](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_Cross-Modal_Implicit_Relation_Reasoning_and_Aligning_for_Text-to-Image_Person_Retrieval_CVPR_2023_paper.pdf)   |CVPR   |https://github.com/anosorae/IRRA|
| 2023  | Person re-identification |Wuhan University|  [Towards Modality-Agnostic Person Re-identification with Descriptive Query](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Towards_Modality-Agnostic_Person_Re-Identification_With_Descriptive_Query_CVPR_2023_paper.pdf)   |CVPR   |https://github.com/ccq195/UNIReID|
| 手机    |   \$12   |   12   |
| 管线    |    \$1    |  234  |
### Visible-Infrared Reidentification
<span id="Pre_training"></span>
## Pre-training
| Date   | keywords   | Institute   | Paper | Publication|  code  |
| :-------:| :-----:  | :----:  |:----:  |:----:  |:----:  |
| 2022  | Vision-and-Language Pre-Training  |The Chinese University of Hong Kong  |  [Multi-Modal Masked Autoencoders for Medical Vision-and-Language Pre-Training](https://arxiv.org/pdf/2209.07098.pdf)   |MICCAI   |  https://github.com/zhjohnchan/M3AE|
| 手机    |   \$12   |   12   |
| 管线    |    \$1    |  234  |
<span id="Prompting_Learning"></span>
## Prompting Learning
| Date   | keywords   | Institute   | Paper | Publication|  code  |
| :-------:| :-----:  | :----:  |:----:  |:----:  |:----:  |
| 2023  | Attributes Prompt  |Harbin Institute of Technology  |  [FashionSAP: Symbols and Attributes Prompt for Fine-grained Fashion Vision-Language Pre-training](https://openaccess.thecvf.com/content/CVPR2023/papers/Han_FashionSAP_Symbols_and_Attributes_Prompt_for_Fine-Grained_Fashion_Vision-Language_Pre-Training_CVPR_2023_paper.pdf)   |CVPR   | https://github.com/hssip/FashionSAP|
| 2022  | Prompt  |Tsinghua University  |  [DenseCLIP: Language-Guided Dense Prediction with Context-Aware Prompting](https://openaccess.thecvf.com/content/CVPR2022/papers/Rao_DenseCLIP_Language-Guided_Dense_Prediction_With_Context-Aware_Prompting_CVPR_2022_paper.pdf)   |CVPR   | https://github.com/raoyongming/DenseCLIP|
| 2023  | Prompt  |  |  [Dual Modality Prompt Tuning for Vision-Language Pre-Trained Model](https://ieeexplore.ieee.org/abstract/document/10171397)   |IEEE Transactions on Multimedia   |  https://github.com/fanrena/DPT|
| 手机    |   \$12   |   12   |
| 管线    |    \$1    |  234  |
<span id="Multimodal_Large_Language_Models"></span>
## Multimodal Large Language Models
| Date   | keywords   | Institute   | Paper | Publication|  code  |
| :-------:| :-----:  | :----:  |:----:  |:----:  |:----:  |
| 2022  | masked image reconstruction |Alibaba |  [Masked Vision-Language Transformer in Fashion](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_Cross-Modal_Implicit_Relation_Reasoning_and_Aligning_for_Text-to-Image_Person_Retrieval_CVPR_2023_paper.pdf)   |Machine Intelligence Research   | https://github.com/GewelsJI/MVLT |
| 手机    |   \$12   |   12   |
| 管线    |    \$1    |  234  |
<span id="Cross_modal_Retrieval"></span>
## Cross-modal Retrieval
| Date   | keywords   | Institute   | Paper | Publication|  code  |
| :-------:| :-----:  | :----:  |:----:  |:----:  |:----:  |
| 2022  | masked image reconstruction |Alibaba |  [Masked Vision-Language Transformer in Fashion](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_Cross-Modal_Implicit_Relation_Reasoning_and_Aligning_for_Text-to-Image_Person_Retrieval_CVPR_2023_paper.pdf)   |Machine Intelligence Research   | https://github.com/GewelsJI/MVLT |
| 手机    |   \$12   |   12   |
| 管线    |    \$1    |  234  |
<span id="Fine_Tuning"></span>
## Fine Tuning
| Date   | keywords   | Institute   | Paper | Publication|  code  |
| :-------:| :-----:  | :----:  |:----:  |:----:  |:----:  |
| 2023  | Fine Tuning |Tsinghua University |  [CogVLM: Visual Expert for Pretrained Language Models](https://arxiv.org/pdf/2311.03079.pdf)   |arXiv   | [https://github.com/GewelsJI/MVLT](https://github.com/THUDM/CogVLM) |
| 手机    |   \$12   |   12   |
| 管线    |    \$1    |  234  |
